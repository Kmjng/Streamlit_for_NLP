# -*- coding: utf-8 -*-
"""
Created on Fri Sep 20 11:12:56 2024

@author: user

# prompt ë¡œ ì‹¤í–‰ 
cd C:/ITWILL/Streamlit_for_NLP
streamlit run app.py
"""

import streamlit as st
#from fts import * 
from collections import Counter
import re
import matplotlib.pyplot as plt

from wordcloud import WordCloud

import nltk
from nltk.corpus import stopwords

import pandas as pd 
from textblob import TextBlob # ê°ì„±ë¶„ì„ì„ ìœ„í•œ NLP ë¼ì´ë¸ŒëŸ¬ë¦¬ 

# ì˜ë¬¸ ë¶ˆìš©ì–´ ì²˜ë¦¬

# NLTK ë¶ˆìš©ì–´ ë‹¤ìš´ë¡œë“œ
nltk.download('stopwords')

# ì‚¬ìš©ì í•¨ìˆ˜ ì •ì˜ 
def extract_words(text):
    # ì •ê·œ í‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ì–´ë§Œ ì¶”ì¶œí•˜ê³  ì†Œë¬¸ìë¡œ ë³€í™˜
    words = re.findall(r'\b\w+\b', text.lower())
    stop_words = set(stopwords.words('english'))
    # ë¶ˆìš©ì–´ë¥¼ ì œì™¸í•œ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    return [word for word in words if word not in stop_words]


st.title("Word Count - ì˜ë¬¸í…ìŠ¤íŠ¸ version")
st.subheader("ë“±ì¥í•œ ë‹¨ì–´ë“¤ì„ ì„¸ì–´ ì¤ë‹ˆë‹¤")

# ì‚¬ìš© ë°©ë²• í”Œë¡œìš° ì°¨íŠ¸
st.subheader("ğŸ’¡ì‚¬ìš© ë°©ë²•")
flowchart = """
digraph {
rankdir=LR;  // ê°€ë¡œ ë°©í–¥ ì„¤ì •
node [shape=box, style=filled, fillcolor="#E0E0E0", height=1.5, width=2.5]; // ë…¸ë“œ ìŠ¤íƒ€ì¼ ë° í¬ê¸° ì„¤ì •
A [label="ì‚¬ìš©ì ì…ë ¥" shape=ellipse fillcolor="#A3C1AD" height=1.5 width=2.5 fontsize=18]; // ê¸€ì”¨ í¬ê¸° ì„¤ì •
B [label="[ë¶„ì„í•˜ê¸°] ë²„íŠ¼ í´ë¦­" shape=ellipse fillcolor="#A3C1AD" height=1.5 width=2.5 fontsize=18];
C [label="ê²°ê³¼ í™•ì¸" shape=ellipse fillcolor="#A3C1AD" height=1.5 width=2.5 fontsize=18];

A -> B -> C;
}
"""
st.graphviz_chart(flowchart)


# ê¸°ëŠ¥ ì¶”ê°€ 
st.write("""
1. ì‚¬ìš©ì ì…ë ¥: ê¸€ì„ ì…ë ¥í•©ë‹ˆë‹¤.
2. 'ë¶„ì„í•˜ê¸°'ë¥¼ ëˆ„ë¥´ë©´ ë“±ì¥í•œ ë‹¨ì–´ê°€ ì¹´ìš´íŠ¸ ë©ë‹ˆë‹¤. 
3. ì˜ë¬¸ì˜ ê²½ìš°, ë¶ˆìš©ì–´ ì²˜ë¦¬ ê¸°ëŠ¥ì´ ë“¤ì–´ê°‘ë‹ˆë‹¤. 
""")

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
user_input = st.text_area("ğŸŸ¢ ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”:")

# ë¶„ì„í•˜ê¸° ë²„íŠ¼
if st.button("ğŸ“¥ë¶„ì„í•˜ê¸°"):
    # ë‹¨ì–´ ì¶”ì¶œ
    words = extract_words(user_input)

    # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
    word_counts = Counter(words)

    # ìì£¼ ë“±ì¥í•œ ë‹¨ì–´ ìˆœì„œëŒ€ë¡œ ì •ë ¬
    most_common_words = word_counts.most_common()

    # ê²°ê³¼ ì¶œë ¥
    if most_common_words:
        st.subheader("ğŸ—¨ï¸ë“±ì¥í•œ ë‹¨ì–´:")
        for word, count in most_common_words:
            st.write(f"{word}: {count}íšŒ")
       
        
        # ë°” ê·¸ë˜í”„ ì¶œë ¥
        words, counts = zip(*most_common_words)  # ë‹¨ì–´ì™€ ì¹´ìš´íŠ¸ë¥¼ ê°ê° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        # Matplotlib ì‚¬ìš©
        st.markdown("#### ğŸ“Šë“±ì¥ ë‹¨ì–´ ì‹œê°í™”")
        plt.figure(figsize=(10, 5))
        plt.barh(words, counts, color='skyblue')  # ê°€ë¡œ ë°” ê·¸ë˜í”„
        plt.xlabel("Count")
        plt.ylabel("Word")
        plt.title("Frequency of words")
        plt.xticks(rotation=45)
        plt.gca().invert_yaxis()  # yì¶• ë°˜ì „
        st.pyplot(plt)  # Streamlitì— Matplotlib ê·¸ë˜í”„ í‘œì‹œ
        
        st.markdown("#### ğŸŒ ë‹¨ì–´ í´ë¼ìš°ë“œ")
        wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_counts)
        
        # ì›Œë“œ í´ë¼ìš°ë“œë¥¼ Matplotlibìœ¼ë¡œ ê·¸ë¦¬ê¸°
        plt.figure(figsize=(10, 5))
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis('off')  # ì¶• ìˆ¨ê¸°ê¸°
        st.pyplot(plt)  # Streamlitì— ì›Œë“œ í´ë¼ìš°ë“œ í‘œì‹œ
        
           
    else:
        st.write("ì…ë ¥ëœ ë¬¸ì¥ì—ì„œ ë‹¨ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


    

st.title("Sentiment Analysis - ì˜ë¬¸ version")
st.subheader("ğŸ’¡ì‚¬ìš© ë°©ë²•")

st.write("""
1. ì‚¬ìš©ì ì…ë ¥: csv íŒŒì¼ì„ ì²¨ë¶€í•©ë‹ˆë‹¤. 
2. ë¦¬ë·°ë‚´ìš©ì˜ ì¹¼ëŸ¼ ì´ë¦„ì€ 'contents' ìœ¼ë¡œ ë§ì¶°ì£¼ì„¸ìš”. 
3. 'ë¶„ì„í•˜ê¸°'ë¥¼ ëˆ„ë¥´ë©´ ë¦¬ë·° ê°ì„± ë¶„ì„ 
""")

# íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯
uploaded_file = st.file_uploader("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="csv")


if uploaded_file is not None:
    # ì—…ë¡œë“œëœ CSV íŒŒì¼ì„ DataFrameìœ¼ë¡œ ì½ê¸°
    df = pd.read_csv(uploaded_file)
    
    # DataFrameì„ í™”ë©´ì— í‘œì‹œ
    st.write("ì—…ë¡œë“œëœ DataFrame:")
    st.dataframe(df)

    # 3. ê°ì„± ë¶„ì„ ìˆ˜í–‰
    if 'contents' in df.columns:
        
        def get_sentiment(text):
            analysis = TextBlob(text)
            return analysis.sentiment.polarity  # ê°ì„± ì ìˆ˜ ë°˜í™˜ (0 ~ 1 ì‚¬ì´)

        # ê°ì„± ë¶„ì„ì„ ì ìš©í•˜ì—¬ ìƒˆë¡œìš´ ì¹¼ëŸ¼ ì¶”ê°€
        df['sentiment'] = df['contents'].apply(get_sentiment)

        # dataframe ì¶œë ¥
        st.write(df[['contents', 'rating', 'sentiment']])
        
        
        positive_reviews = df[(df['sentiment'] > 0) & (df['sentiment'] <= 1)]
        negative_reviews = df[df['sentiment'] < 0]

        # p/n ì¶œë ¥
        st.write(f"ğŸ‘ê¸ì • ë¦¬ë·°: {len(positive_reviews)}ê°œ")
        st.write(f"ğŸ‘ë¶€ì • ë¦¬ë·°: {len(negative_reviews)}ê°œ")
    else:
        st.error("DataFrameì—ëŠ” 'contents' ì¹¼ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")





